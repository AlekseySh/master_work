\section{Искуственные нейронные сети}

\indent
\indent
Настоящая часть работы предназначена для читателя, не знакомого с 
искуственными нейронными сетями и глубоким обучением. 
Здесь будут приведены теоретические 
основы глубокого обучения и рассмотрены сверточные архитектуры, 
используемые в дальнейшей работе.


\subsection{Перцептрон}

\indent
Начнем с рассмотрения одиночного нейрона
 --- перцептрона Розенблатта --- базового элемента, содержащегося в большинстве современных нейросетевых архитектур.
Перцептрон имеет несколько входов и один выход, значение на котором
вычисляется как взвешенная сумма значений входов 
(рисунок \ref{tikzpicture: perceptron}).
Кроме того, обычно
к выходному значению применяется сдвиг и некоторая нелинейная функция, 
называющаяся функцией активации нейрона. Ее предназначение мы обсудим позже.

\begin{figure}[h!]
    \begin{center}
   	    \includegraphics[width=0.6\linewidth]{Perceptron}
   	\end{center}
   	\caption{Схематическое изображение работы одного отдельного нейрона.}
   	\label{tikzpicture: perceptron}
\end{figure}


\indent
\indent
Таким образом, значение на выходе нейрона задается
 выражением \ref{eq:perceptron}.

\begin{equation}\label{eq:perceptron}
    f(\vec{x}) = A(\sum_{i=1}^n x_i w_i + b)
\end{equation}


где $f(\vec{x})$ -- выходное значение нейрона, посчитанное для входов $x_i$,
$w_i$ -- весовые коэффициенты для каждого входа, $b$ -- параметр смещения, 
а $A$ --- нелинейная функция активации. Далее для упрощения повествования
положим $b \equiv 0$.

\subsection{Функции активации}

\indent
\indent
Существуют множество различных функций активации, например, гиперболический
тангенс, логистическая сигмоида или \textit{ReLU}, рисунок \ref{tikzpicture: activations}.

\begin{equation}\label{eq:activations}
	\begin{gathered}
	    A_{1}(x) = th(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}},    \;   th’(x) = {1 - th(x)^2}  \\    
	    A_{2}(x) = \sigma(x) = \frac{1}{1 + e^{-2x}},   \;   \sigma’(x) = \sigma(x)(1 - \sigma(x)) \\
	    A_{3}(x) = ReLU = max(0, x),   \;   ReLU’(x) = \theta(x)
	\end{gathered}
\end{equation}
где $\theta(x)$ -- функция Хэвисайда.

\indent
\indent
Эти функции используются
для добвления нелинейных зависимостей между слоями многослойной модели.
Названные выше функции особенно популярны, 
так как значения их производных либо достаточно просты, либо легко 
выражаются через значения самих функций (выражение \ref{eq:activations}), 
что позволяет быстро вычислять значение производной.

\begin{figure}[h!]
	\begin{center}
		\begin{tikzpicture}
			\begin{axis} [
			    legend pos = north west, 
			    xmin = -2,
			    xmax = 2,
			    minor tick num = 2
			]
			\legend{ 
				$th(x)$, 
				$\sigma(x)$, 
				$ReLU(x)$
			};
			\addplot[blue, line width = 1.5] {tanh(x)};
			\addplot[red, line width = 1.5] {1 / (1 + e^(-2*x))};
			\addplot[green, line width = 1.5] {max(0, x)};
			\end{axis}
		\end{tikzpicture}
	\end{center}
\caption{Функции активации}
\label{tikzpicture: activations}
\end{figure}

\subsection{Полносвязная сеть}

\indent
\indent
Одиночный нейрон не способен выразить сложные в наборе
признаков $\vec{x}$, поэтому нейроны объединяют в слои, а их, в свою 
очередь, в многослойные сети . Рассмотрим сеть,
состоящую из двух слоев нейронов. Пусть количество количество входных признаков
равно $N$, количество нейронов скрытого слоя $P$,
а размер выхода -- $M$, рисунок \ref{tikzpicture: fc_net}. Такая архитектура, 
состоящая из простых линейных слоев, называется полносвязной.
 
\begin{figure}[h!]
    \begin{center}
   	    \includegraphics[width=0.9\linewidth]{FC_net}
   	\end{center}
   	\caption{Схематическое изображение полносвязной нейронной сети.}
   	\label{tikzpicture: fc_net}
\end{figure}

Рассмотрев выражение \ref{eq:perceptron} можно увидеть, что 
совокупность значений нейронов на 1 слое может быть получена 
простым матричным умножением входов $\vec{x}$ на матрицу весов
 $W^1$ размера $P \times N$, с последующим поэлементным применением 
функции активации к получившися значениям. Аналогично, значения нейронов
2 слоя получаются умножением предыдущих значений на весовую матрицу
$W^2$ размером $M \times P$. Таким образом, применение нейросети
ко входу $\vec{x}$ можно задать выражением \ref{eq:forward}.

\begin{equation}\label{eq:forward}
	   \vec{y} = A(W^{2} A(W^{1} \vec{x}))
\end{equation}
где $A(\cdot)$ -- применение нелинейности к каждому элементу входного 
вектора.

\indent
\indent
Если бы мы не добавляли после слоев нелинейность, то выражение \ref{eq:forward}
выродилось бы в простое умножение слева входного вектора $\vec{x}$ на матрицу
$W^{12} \equiv W^{2} W^{1}$. В этом случае модель не смогла бы выучить 
сложные нелинейные зависимости в данных, а добавление дополнительных слоев
не имело бы смысла, т.к. все они могут быть описаны одной матрицей весов.


\subsection{Функции потерь}

\indent
\indent
Близость предсказания сети к правильным ответам оценивается
с помощью функции ошибки, так же называемой 
 функцией потерь \textit{(loss function)}. 
Например, для задачи регресии в качестве функции потерь
может применяться сумма квадратов отклонений
 (выражение \ref{eq: se}),
 или, в более простом случае -- сумма разностей между выходами модели
  и правильными ответами (выражение \ref{eq:diff});
для задачи классификации обычно используют перекрестную энтропию 
(\textit{cross entropy}, выражение \ref{eq: cross_entropy}).


\begin{equation}\label{eq:diff}
    L_{diff}(\vec{y_{gt}}, \vec{y}) = \sum_{i=1}^M | y^{gt}_{i} - y_{i} |
\end{equation}

\begin{equation}\label{eq: se}
    L_{mse}(\vec{y_{gt}}, \vec{y}) = \frac{1}{2} \sum_{i=1}^M (y^{gt}_{i} - y_{i})^2
\end{equation}

\begin{equation}\label{eq: cross_entropy}
    L_{ce}(\vec{y_{gt}}, \vec{y}) = - \sum_{i=1}^M y_{i} \log{y^{gt}_{i}}
\end{equation}

\indent
\indent
Исходя из постановки решаемой задачи, можно составить и другие функции ошибок, но
они обязательно должны быть дифференциируемыми.
Это необходимо условие, чтобы использовать метод обратного распространения
ошибки для обучения модели.


\subsection{Обучение нейронных сетей}
% https://habr.com/ru/company/ods/blog/344116/
% https://ru.wikipedia.org/wiki/Метод_обратного_распространения_ошибки

\indent
\indent
Обучение нейронной сети -- это процесс изменения весовых
коэффициентов между нейронами, направленный на уменьшение
 значения функции потерь на тренировочном наборе данных $\{ \vec{x} | \vec{y} \}$. 
 Мы рассмотрим базовую реализацию такого процесса -- алгоритм 
 стохастического градиентного спуска. Мы будем подавать на вход модели
 размеченные тренировочные данные, объединенные в  небольшие партии 
 \textit{(batches)}. Идея состоит в том в том, чтобы после каждой такой партии
добавлять ко всем весам поправку, противоположную градиенту от функции потерь
(выражение \ref{eq: grad_idea}). 
Отметим, что метод называется стохастическим, так как веса 
модели обновляются после каждой партии данных. Из-за этого
направление, в котором делается шаг по профилю функции потерь,
не является оптимальным для обучающего набора данных в целом.
Можно интепретировать названный факт как добавление шума
к вычисляемому градиенту, отсюда и стохастичность.


\begin{equation}\label{eq: grad_idea}
    w_{i, j} \leftarrow w_{i, j} - \Delta w_{i,j} = - v \frac{\partial L}{\partial w_{i, j}}
\end{equation}
где $v \in (0; 1)$ -- параметр, отвечающий за скорость обучения \textit{(learning rate)}.

Для начала положим, что $j$ является 
нейроном последнего слоя. Обозначим $S_{j} = \sum_{i} w_{i, j} x_{i}$ и
распишем производную из выражения \ref{eq: grad_idea}.

\begin{equation}\label{eq: derivs}
    \frac{\partial L}{\partial w_{i, j}} = 
    \frac{\partial L}{\partial S_j} \frac{\partial S_j}{\partial w_{i, j}} =
    x_i \frac{\partial L}{\partial S_j} =
    x_i \frac{\partial L}{\partial y_j} \frac{\partial y_j}{\partial S_j} =
    x_i \frac{\partial L}{\partial y_j}  \frac{\partial A(S)}{\partial S} | S_j
\end{equation}

Чтобы сосчитать производные в выражении \ref{eq: derivs} осталось выбрать какие-то конкретные
функции потерь и активации. Выберем в качестве фунции активации $A$ 
логистическую сигмоиду $\sigma$ (формула \ref{eq:activations}), а в качестве функции потерь
$L$ -- квадратичное отклонение (формула \ref{eq: se}). После подстановки получим
окончательную формулу для обновления весов последнего слоя (формула \ref{eq: weights_upd}).

\begin{equation}\label{eq: weights_upd}
    w_{i, j} \leftarrow w_{i, j} - 2 v x_i y_j (1 - y_j) (y^{gt}_j - y_j)
\end{equation}

Рассмотрим случай, когда $j$-й узел находится во внутренних слоях и 
у него есть выходы (обозначим их как \textit{childrens(j)}).

\begin{equation}\label{eq: childrens}
    \frac{\partial L}{\partial S_j} = 
    \sum_{k \in childrens(j)} \frac{\partial L}{\partial S_k} \frac{\partial S_k}{\partial S_j} 
\end{equation}


\indent
\indent
В выражении \ref{eq: childrens} можно явно сосчитать 
$\frac{\partial S_k}{\partial S_j}$, в нашем случае мы получим 
$2 w_{j, k} y_j (1 - y_j)$, а $\frac{\partial L}{\partial S_k}$ -- это поправка для весов, вычисленная для узла 
следующего уровня (с точностью до коэффициента $-v x_i$). Таким образом, мы можем вычислить
поправку для весов нейронов последнего уровня (выражение \ref{eq: weights_upd}), и использовать
её, чтобы вычислить поправки для остальных уровней
(выражение \ref{eq: childrens}). Из-за вычислений такого вида
 данный подход так же называют алгоритмом обратного распространения ошибки \textit{(backpropogation)}.
 

\subsection{Сверточные нейронные сети}
\indent
\indent
Сверточная неройнная сеть \textit{(Convolution neural network, CNN)} --- 
это специальная сеть, изначально сконструированная для 
обработки изображений, хотя в настоящее время спектр их применения 
значительно расширился. Как следует из названия, основной таких сетей 
являются сверточные слои \textit{(convolutional layers)}.
Кроме того, обычно вместе с ними используются такие
слои как \textit{BatchNormalization}, \textit{Pooling}, \textit{Softmax} и \textit{Dropout}.

\indent
\indent
Рассмотрим, как устроено применение оператора свертки к изображению.
% https://habr.com/ru/company/ods/blog/344008/

\subsection{Используемые сверточные архитектуры}
\indent
\indent
В данное работе используются следующие архитектуры нейронных сетей:


\begin{itemize}

    \item \textit{Residual netwrotk (ResNet)} ---
    одна из самых популярных в настоящее время архитектур,
    предложенная в статье \cite{resnet} 2015 года.
    Основная идея состоит в добавлении конкатенации значений
    нейронов слоя с номером  $i$ и слоя $i - 2$ (такая процедура
    получила название \textit{skip connection}. Таким образом авторы
    успешно решают распространенную проблему 
    обучения глубоких сетей --- затухание градиентов.
    
    \item {Inception} --- todo
    
    \item {DenseNet} --- todo
    
    \item {VGG} --- относительно старая, ставшая классической, архитектура,
    предложенная в 20хх году todo.
    
\end{itemize}

